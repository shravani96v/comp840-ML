{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Learning Seattle's Work Habits from Bicycle Counts Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook originally appeared as a [post](http://jakevdp.github.io/blog/2015/07/23/learning-seattles-work-habits-from-bicycle-counts/) by Jake VanderPlas on the blog [Pythonic Perambulations](http://jakevdp.github.io) and [the related video series](http://jakevdp.github.io/blog/2017/03/03/reproducible-data-analysis-in-jupyter/)  Also adapted from by Amit Aides's \"Intro session to data science with Python\". \n",
    "\n",
    "\n",
    "\n",
    "The content is MIT licensed.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Data\n",
    "\n",
    "The data we will use here are the hourly bicycle counts on Seattle's Fremont Bridge. \n",
    "\n",
    "A time series is any data set where the values are measured at different points in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: \n",
    "\n",
    "Understand the bike data.  Learn how to use curl command to download data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#!curl -o FremontBridge.csv https://data.seattle.gov/api/views/65db-xm6k/rows.csv?accessType=DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('FremontBridge12-16.csv', index_col='Date', parse_dates=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We'll do some quick data cleaning: we'll rename the columns to the shorter \"West\" and \"East\", set any missing values to zero, and add a \"Total\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data.columns = ['West', 'East']\n",
    "data.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: \n",
    "\n",
    "Add a new column of total which is the sum of east and west bike count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do:\n",
    "# data['Total'] = \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualize the Data\n",
    "\n",
    "With matplotlib and seaborn, we can visualize our Pandas time series data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first some standard imports\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn; \n",
    "seaborn.set()  # plot styling\n",
    "seaborn.set_context(font_scale=1.5)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "data.resample('W').sum().plot(figsize=(8, 8))\n",
    "plt.ylabel('weekly trips');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3: \n",
    "\n",
    "Since the data is a time serie and is indexed by a timestamp, we can resample the data at a different frequency. Now resample the data to have the monthly total.  Plot out results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: \n",
    "# data.resample ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group the data by the 12 monthes and plot out the mean.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(data.index.month).mean().plot(figsize=(8, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4: \n",
    "\n",
    "Group the data by the time (24 hours) and plot out the mean.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Unsupervised Learning Extracting: Knowledge from the Data\n",
    "\n",
    "From here, we could do a variety of other visualizations based on our intuition about what might affect bicycle counts. And we could also proceed by letting the dataset speak for itself, and use *unsupervised machine learning* techniques (that is, machine learning without reference to data labels) to learn what the data have to tell us.\n",
    "\n",
    "We will consider each day in the dataset as a sample. \n",
    "For each day, we have 48 observations: two observations (east and west sidewalk sensors) for each of the 24 hour-long periods. The goal is to find out how what differen kinds of days are there relavent to the bike traffic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Transforming the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = data.pivot_table(['East', 'West'],\n",
    "                           index=data.index.date,\n",
    "                           columns=data.index.hour)\n",
    "pivoted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's check the first 5 records from the East sidewalk counter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five_east = pivoted.iloc[:5, :24]\n",
    "first_five_east"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5: \n",
    "In the pivot table, slice the first 5 records from the West bound traffic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do:\n",
    "# first_five_west ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to figure out some patterns from the data. Let's start with the first five east bound records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five_east.plot(figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try transpose the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_five_east.T.plot(figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the data collected east bound for all the dates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "east = pivoted.iloc[:, :24]\n",
    "east.T.plot(legend=False, alpha=0.01, figsize=(8, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6:\n",
    "\n",
    "Plot all the records from the West bound counter for all the dates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do:\n",
    "# west = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots give us some insight into the data. It looks like there are two types of clusters: the first cluster shows a sharp bimodal traffic pattern, while the second shows a wide unimodal pattern. In the bimodal cluster, we see a peak in the morning and another peak in the afternoon which is clearly a commute pattern. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Dimensionality Reduction\n",
    "\n",
    "We can think of this data now as representing more than 1000 distinct objects which live in a *48-dimensional* space: the value of each dimension is the number of bicycle trips measured on a particular side of the bridge at a particular hour.\n",
    "Visualizing 48-dimensional data is quite difficult, so instead we will use a standard *dimensionality reduction* technique to project this to a more manageable size.\n",
    "\n",
    "The technique we'll use is [Principal Component Analysis (PCA)](http://scikit-learn.org/stable/modules/decomposition.html), a fast linear projection which rotates the data such that the projection preserves the maximum variance.\n",
    "We can ask for components preserving 90% of the variance as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first extract the raw values and put them in a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X = pivoted.values\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#Xpca = PCA(n_components=2).fit_transform(X)\n",
    "Xpca = PCA(0.90, svd_solver='full').fit_transform(X)\n",
    "Xpca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "The output has two dimensions, which means that these two projected components describe at least 90% of the total variance in the dataset.\n",
    "While 48-dimensional data is difficult to plot, we certainly know how to plot two-dimensional data: we'll do a simple scatter plot, and for reference we'll color each point according to the total number of trips taken that day:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7:\n",
    "\n",
    "In this PCA analysis above, how many projected components are needed to describe at least 95% of the total variance in the dataset? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(Xpca[:,0], Xpca[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "total_trips = X.sum(1)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(\n",
    "    Xpca[:, 0],\n",
    "    Xpca[:, 1],\n",
    "    c=total_trips,\n",
    "    cmap='jet'\n",
    ")\n",
    "\n",
    "plt.colorbar(label='total trips');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We see that the days lie in two quite distinct groups, and that the total number of trips increases along the length of each projected cluster.\n",
    "Further, the two groups begin to be less distinguishable when the number of trips during the day is very small.\n",
    "\n",
    "I find this extremely interesting: from the raw data, we can determine that there are basically *two primary types of days* for Seattle bicyclists.\n",
    "Let's model these clusters and try to figure out what these types-of-day are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Unsupervised Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "When you have groups of data you'd like to automatically separate, but no previously-determined labels for the groups, the type of algorithm you are looking at is a *clustering* algorithm.\n",
    "There are a number of clustering algorithms out there, but for nicely-defined oval-shaped blobs like we see above, [Gaussian Mixture Models](http://scikit-learn.org/stable/modules/mixture.html) are a very good choice.\n",
    "We can compute the Gaussian Mixture Model of the data using, again, scikit-learn, and quickly plot the predicted labels for the points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture \n",
    "gmm = GaussianMixture(n_components=2, covariance_type='full', random_state=0)\n",
    "gmm.fit(Xpca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_label = gmm.predict(Xpca)\n",
    "cluster_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "for i, color in enumerate(['black', 'red']):\n",
    "    inds = cluster_label == i\n",
    "    x, y = Xpca[inds, 0], Xpca[inds, 1]\n",
    "    plt.scatter(x, y, c=color, label=\"Cluster {}\".format(i),\n",
    "               edgecolors='none')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "This clustering seems to have done the job, and separated the two groups we are interested in.\n",
    "Let's join these inferred cluster labels to the initial dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pivoted['Cluster'] = cluster_label\n",
    "data = data.join(pivoted['Cluster'], on=data.index.date)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find the average trend by cluster and time using a GroupBy within this updated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "by_hour = data.groupby(['Cluster', data.index.time]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_hour.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_hour.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Finally, we can plot the average hourly trend among the days within each cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "hourly_ticks = 4 * 60 * 60 * np.arange(6)\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()[:2]):\n",
    "    by_hour.loc[i].plot(y=\"West\", ax=ax, xticks=hourly_ticks)\n",
    "    by_hour.loc[i].plot(y=\"East\", ax=ax, xticks=hourly_ticks)\n",
    "    ax.set_title('Cluster {0}'.format(i))\n",
    "    ax.set_ylabel('average hourly trips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "These plots give us some insight into the interpretation of the two clusters: the first cluster shows a sharp bimodal traffic pattern, while the second shows a wide unimodal pattern.\n",
    "\n",
    "In the bimodal cluster, we see a peak around 8:00am which is dominated by cyclists on the west sidewalk, and another peak around 5:00pm which is dominated by cyclists on the east sidewalk.\n",
    "This is very clearly a commute pattern, with the majority of cyclists riding toward downtown Seattle in the morning, and away from downtown Seattle in the evening.\n",
    "\n",
    "In the unimodal cluster, we see fairly steady traffic in each direction beginning early in the morning and going until late at night, with a peak around 2:00 in the afternoon.\n",
    "This is very clearly a recreational pattern of use, with people out riding through the entire day.\n",
    "\n",
    "This is quite fascinating: from simple unsupervised dimensionality reduction and clustering, we've discovered two distinct classes of days in the data, and found that these classes have very intuitive explanations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Seattle's Work Habits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Let's go one step deeper and figure out what we can learn about people (well, bicycle commuters) in Seattle from just this hourly commute data.\n",
    "As a rough approximation, you might guess that these two classes of data might be largely reflective of workdays in the first cluster, and non-work days in the second.\n",
    "We can check this intuition by re-plotting our projected data, except labeling them by day of the week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayofweek = pd.to_datetime(pivoted.index).dayofweek\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(Xpca[:, 0], Xpca[:, 1], c=dayofweek,\n",
    "            cmap=plt.cm.get_cmap('jet', 7))\n",
    "cb = plt.colorbar(ticks=range(7))\n",
    "cb.set_ticklabels(['Mon', 'Tues', 'Wed', 'Thurs', 'Fri', 'Sat', 'Sun'])\n",
    "plt.clim(-0.5, 6.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "We see that the weekday/weekend intuition holds, but only to a point: in particular, it is clear that **there are a handful of weekdays which follow the typical weekend pattern!**\n",
    "Further, it's interesting to note that Fridays tend to be pulled closer to weekend days in this plot, though as a whole they still fall solidly in the work-day cluster.\n",
    "\n",
    "Let's take a closer look at the \"special\" weekdays that fall in the \"wrong\" cluster.\n",
    "We start by constructing a dataset listing the cluster id and the day of the week for each of the dates in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame({'cluster': cluster_label,\n",
    "                        'is_weekend': (dayofweek > 4),\n",
    "                        'weekday': pivoted.index.map(lambda x: x.strftime('%a'))},\n",
    "                       index=pivoted.index)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "results[results[\"cluster\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[results[\"cluster\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekend_workdays = results.query('cluster == 0 and is_weekend')\n",
    "len(weekend_workdays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, there is not a single weekend during the year where Seattle cyclists as a whole decide to go to work.  Similarly, we can see how many weekdays fall in the second, recreation-oriented cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midweek_holidays = results.query('cluster == 1 and not is_weekend')\n",
    "len(midweek_holidays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midweek_holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "cal = USFederalHolidayCalendar()\n",
    "holidays = cal.holidays('2012', '2016', return_name=True)\n",
    "holidays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for completeness, we will add to the list the day before and day after each of these holidays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_all = pd.concat([holidays,\n",
    "                         \"Day Before \" + holidays.shift(-1, 'D'),\n",
    "                         \"Day After \" + holidays.shift(1, 'D')])\n",
    "holidays_all = holidays_all.sort_index()\n",
    "holidays_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
